import pandas as pd
from scrape_all_data import extract_weather_data, transform_weather_data
from bigquery_utils import (
    setup_bigquery_client,
    create_dataset_if_not_exists,
    upload_dataframe_to_bigquery,
    verify_upload
)

def fetch_and_upload_weather_data(key_path, dataset_id="singapore_datasets"):
    """Fetch and upload weather data to BigQuery"""
    # Setup BigQuery client
    bq_client, project_id = setup_bigquery_client(key_path)
    
    # Create dataset if it doesn't exist
    create_dataset_if_not_exists(bq_client, project_id, dataset_id)
    
    # Extract weather data
    print("=== EXTRACTING WEATHER DATA ===")
    weather_data = extract_weather_data()
    
    # Transform weather data
    print("=== TRANSFORMING WEATHER DATA ===")
    weather_df = transform_weather_data(weather_data)
    
    # Upload weather data to BigQuery
    print("=== UPLOADING WEATHER DATA TO BIGQUERY ===")
    upload_dataframe_to_bigquery(
        bq_client,
        weather_df,
        project_id,
        dataset_id,
        "weather_rainfall"
    )
    verify_upload(bq_client, project_id, dataset_id, "weather_rainfall")
    print(f"âœ… weather_rainfall: {len(weather_df)} rows uploaded successfully")
    
    print("=== WEATHER DATA UPLOAD COMPLETE ===")

if __name__ == "__main__":
    # Path to your service account key file
    key_path = "../../key/is3107-457309-0e9066063708.json"
    
    # Dataset name in BigQuery
    dataset_id = "singapore_datasets"
    
    # Fetch and upload weather data
    fetch_and_upload_weather_data(key_path, dataset_id)